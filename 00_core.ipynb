{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Cells will be exported to syntheticReplica.core,\n",
      "unless a different module is specified after an export flag: `%nbdev_export special.module`\n"
     ]
    }
   ],
   "source": [
    "%nbdev_hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nbdev import *\n",
    "%nbdev_default_export core\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.nb_imports import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_hide\n",
    "# IN_COLAB = 'google.colab' in str(get_ipython())\n",
    "# if IN_COLAB:\n",
    "#   !pip install git+https://github.com/pete88b/nbdev_colab_helper.git\n",
    "#   from nbdev_colab_helper.core import *\n",
    "#   project_name = 'syntheticReplica'\n",
    "#   init_notebook(project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%nbdev_export\n",
    "from syntheticReplica.dirView import *\n",
    "from syntheticReplica.display import *\n",
    "from syntheticReplica.utils import *\n",
    "\n",
    "import collections \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "import pandas as pd\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from shapely.geometry import Polygon, MultiPolygon\n",
    "from skimage import measure\n",
    "\n",
    "@dataclass\n",
    "class PreviewFore(UtilsBuildLinearCoord):\n",
    "    path_dir: Path\n",
    "    file_csv: str \n",
    "    file_image: Path\n",
    "    dataframe_path: Path = field(init=False, repr=False)\n",
    "    path_image: Path = field(init=False, repr=False)\n",
    "\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.dataframe_path: Path = Path(self.path_dir).joinpath(self.file_csv)\n",
    "        self.path_image: Path = Path(self.path_dir).joinpath(self.file_image)\n",
    "        df = pd.DataFrame(columns = ['init_pto_x', 'init_pto_y', 'expand_x', 'expand_y'], dtype=np.int16) \n",
    "        df.to_csv(self.dataframe_path, index=True)\n",
    "        #return self.dataframe_path, self.path_image \n",
    "\n",
    "    def petriAnnot(self, init_pto, expand_x=1, expand_y=1):\n",
    "        fig = plt.figure()\n",
    "        image_show = UtilsBuildLinearCoord.openImg(self.path_image)\n",
    "        ax = plt.gca()\n",
    "        # Todo, set max counter to 8\n",
    "        counter = 0\n",
    "        for init, x, y in zip(init_pto, expand_x, expand_y):\n",
    "            _x, _y = UtilsBuildLinearCoord.buildAnnotPoint(init, x, y)\n",
    "            generate = UtilsBuildLinearCoord.convertMatplot(init, _x, _y)\n",
    "            store_ptos = UtilsBuildLinearCoord.storeXY(generate)\n",
    "            color = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w' ]\n",
    "            ax.plot(store_ptos[0], store_ptos[2], '-', color=color[counter])\n",
    "            ax.plot(store_ptos[1], store_ptos[3], '-', color=color[counter])\n",
    "            ax.plot(init[0], init[1], marker='o', color=color[counter])\n",
    "            #ax.text(init[0]-18, init[1]-18, str(counter))\n",
    "            # Todo: convert text(above line) to color or coordinate\n",
    "            x_show = (init[0])\n",
    "            y_show = (init[1])\n",
    "            ax.text(init[0]-18, init[1]-18, (x_show, y_show))\n",
    "            #ax.text(init[0]-18, init[1]-18, color[counter])\n",
    "\n",
    "            counter += 1\n",
    "        plt.imshow(image_show)\n",
    "        plt.show()\n",
    "\n",
    "    # Todo, show image size\n",
    "    def adPto(self, index:str, init_pto:list, expand_x=1, expand_y=1) -> None:\n",
    "        df_addPto = pd.read_csv(self.dataframe_path, index_col=0) \n",
    "        x_pto = init_pto[0]\n",
    "        y_pto = init_pto[1]\n",
    "        df_addPto.loc[index] = {'init_pto_x':x_pto, 'init_pto_y':y_pto, 'expand_x':expand_x, 'expand_y':expand_y}\n",
    "        df_addPto.to_csv(self.dataframe_path, index=True)\n",
    "        print(df_addPto.head(8))\n",
    "        init_pto, expand_x, expand_y = UtilsBuildLinearCoord.col2List(self.dataframe_path)\n",
    "        self.petriAnnot(init_pto, expand_x, expand_y)\n",
    "    \n",
    "    def rmPto(self, index:str ) -> None:\n",
    "        df_remPto = pd.read_csv(self.dataframe_path, index_col=0)\n",
    "        df_remPto.drop([index], inplace=True)\n",
    "        df_remPto.to_csv(self.dataframe_path, index=True)\n",
    "        print(df_remPto.head(8))\n",
    "        update_init_pto, update_expand_x, update_expand_y = UtilsBuildLinearCoord.col2List(self.dataframe_path)\n",
    "        self.petriAnnot(update_init_pto, update_expand_x, update_expand_y)    \n",
    "\n",
    "# Todo: add parameters for multiple supercategory, category_id, category_name\n",
    "@dataclass\n",
    "class SyntheticImageBuild():\n",
    "    image_id: int\n",
    "    fname_train: str\n",
    "    path_train: Path\n",
    "    original_background: Path\n",
    "    path_annotation_file: Path\n",
    "    synthetic_train_path: Path = field(init=False, repr=False)\n",
    "    is_crowd: int = field(default=0)\n",
    "    category_zone: int = field(default=0)\n",
    "    category_disk: int = field(default=1)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.synthetic_train_path = Path(self.path_train).joinpath(self.fname_train)\n",
    "        self.back_img_size = imageSize(str(self.original_background))\n",
    "        self.index_name_list, self.coordinates_list = randomCoordinates(self.path_annotation_file)\n",
    "\n",
    "    def buildImage(self):\n",
    "        foreground_sequence = [fore_zone, fore_disk, fore_disk]\n",
    "        counter = 0\n",
    "        result = []\n",
    "        \n",
    "        for i in range(len(self.coordinates_list)):\n",
    "            coord = self.coordinates_list[i]\n",
    "            random_pick = list(map(lambda x: random.choices(x), foreground_sequence))\n",
    "            first_selection = [random_pick[0] + random_pick[1]]\n",
    "            second_selection = [random_pick[2]]\n",
    "            selection = [first_selection, second_selection]\n",
    "            _pick = random.choice(random.choices(selection, weights=map(len, selection))[0]) # dtype:list\n",
    "            pick_size = list(_pick)\n",
    "\n",
    "            if len(pick_size) == 1:\n",
    "                #print(f'length 1 {_pick[0]}')\n",
    "                if counter == 0:\n",
    "                    # back = background_original\n",
    "                    bbox, area, segmentation, index_name  = imgCompSegBbox(_pick[0], coord, self.back_img_size, self.original_background, fname_train, train_path, self.index_name_list[i])\n",
    "                    counter += 1\n",
    "                    result.append([segmentation, self.is_crowd, area, self.image_id, bbox, self.category_disk, counter])\n",
    "                elif counter >= 1:\n",
    "                    # back = background_train\n",
    "                    bbox, area, segmentation, index_name = imgCompSegBbox(_pick[0], coord, self.back_img_size, self.synthetic_train_path, fname_train, train_path, self.index_name_list[i])\n",
    "                    counter += 1\n",
    "                    result.append([segmentation, self.is_crowd, area, image_id, bbox, self.category_disk, counter])\n",
    "                                    \n",
    "            elif len(pick_size) == 2:\n",
    "                #print(f'length 2 {_pick}')\n",
    "                # starts with background_original\n",
    "                if counter == 0:\n",
    "                    # background_original, _pick[0]\n",
    "                    bbox_zone, area_zone, segmentation_zone, index_name_zone = imgCompSegBbox(_pick[0], coord, self.back_img_size, self.original_background, fname_train, train_path, self.index_name_list[i])\n",
    "                    counter += 1\n",
    "                    result.append([segmentation_zone, self.is_crowd, area_zone, self.image_id, bbox_zone, self.category_zone, counter])\n",
    "\n",
    "                    coord_disk = findCoord(_pick, coord)\n",
    "                    bbox_disk, area_disk, segmentation_disk, index_name_disk = imgCompSegBbox(_pick[1], coord_disk, self.back_img_size, self.synthetic_train_path, fname_train, train_path, self.index_name_list[i])\n",
    "                    counter += 1\n",
    "                    result.append([segmentation_disk, self.is_crowd, area_disk, self.image_id, bbox_disk, self.category_disk, counter])\n",
    "                                    \n",
    "                # starts with background_train\n",
    "                elif counter >= 1:\n",
    "                    # background_train, pick[0]\n",
    "                    bbox_zone, area_zone, segmentation_zone, index_name_zone = imgCompSegBbox(_pick[0], coord, self.back_img_size, self.synthetic_train_path, fname_train, train_path, self.index_name_list[i])\n",
    "                    counter += 1\n",
    "                    result.append([segmentation_zone, self.is_crowd, area_zone, self.image_id, bbox_zone, self.category_zone, counter])\n",
    "                                    \n",
    "                    # background_train, pick[1]\n",
    "                    coord_disk = findCoord(_pick, coord)\n",
    "                    bbox_disk, area_disk, segmentation_disk, index_name_disk = imgCompSegBbox(_pick[1], coord_disk, self.back_img_size, self.synthetic_train_path, fname_train, train_path, self.index_name_list[i])\n",
    "                    counter += 1\n",
    "                    result.append([segmentation_disk, self.is_crowd, area_disk, self.image_id, bbox_disk, self.category_disk, counter])\n",
    "        return result\n",
    "        \n",
    "    def _annotJSON(self,_result):\n",
    "        dict_res = []\n",
    "        for i in range(len(_result)):\n",
    "            dict_list = addAnnotDict(segmentation=_result[i][0], \n",
    "                        iscrowd=_result[i][1], \n",
    "                        area=_result[i][2], \n",
    "                        image_id=_result[i][3], \n",
    "                        bbox=_result[i][4], \n",
    "                        category_id=_result[i][5], \n",
    "                        id=_result[i][6])\n",
    "            \n",
    "            annot_res = dict_list['annotations'][0]\n",
    "            dict_res.append(annot_res)\n",
    "        return dict_res   \n",
    "    \n",
    "    def _imageJSON(self):\n",
    "        images_dic = addImagesDict(self.path_train, self.fname_train, self.image_id)\n",
    "        return images_dic['images'][0]\n",
    "\n",
    "    # Todo: add parameters for multiple supercategory, category_id, category_name\n",
    "    # Make sure you can execute this only once.  Use yield!\n",
    "    def _catJSON(self):\n",
    "        # First category\n",
    "        supercategory = \"none\"\n",
    "        id_zone = 0\n",
    "        name_zone = \"zone\"\n",
    "        category_zone_dict = addCatDict(supercategory, id_zone, name_zone)\n",
    "        zone_dict = (category_zone_dict['categories'][0])\n",
    "        # Second category\n",
    "        supercategory = \"none\"\n",
    "        id_disk = 1\n",
    "        name_disk = \"disk\"\n",
    "        category_disk_dict = addCatDict(supercategory, id_disk, name_disk)\n",
    "        disk_dict = (category_disk_dict['categories'][0])\n",
    "        # Make sure you execute this only once, otherwise it will append new categories.\n",
    "        categories_dict = {'categories':[]}\n",
    "        categories_dict['categories'].append(zone_dict)\n",
    "        categories_dict['categories'].append(disk_dict)\n",
    "        cat_0 = categories_dict['categories'][0]\n",
    "        cat_1 = categories_dict['categories'][1]\n",
    "        return [cat_0, cat_1]\n",
    "\n",
    "    def JSON2COCO(self, json_fname):\n",
    "        coco_json = {\"images\":[], \"categories\":[], \"annotations\":[]}\n",
    "        coco_json['images'].append(self._imageJSON())\n",
    "        coco_json['categories'].append(self._catJSON()[0])\n",
    "        coco_json['categories'].append(self._catJSON()[1])\n",
    "        \n",
    "        #annotations_coco = [annot_dict_AML_25, annot_dict_CT5_zone, annot_dict_CT25_diskZone]\n",
    "        annotations_coco = self._annotJSON(self.buildImage())\n",
    "        for _annot in annotations_coco:\n",
    "            coco_json['annotations'].append(_annot)\n",
    "\n",
    "        # Save to image annotation in coco_annotation directory.\n",
    "        json_coco = json.loads(json.dumps(coco_json, indent=4))\n",
    "        synthetic_json = coco_annot_path.joinpath(json_fname)\n",
    "        with open(synthetic_json, 'w') as coco:\n",
    "            json.dump(json_coco, coco, indent=4)\n",
    "    \n",
    "        return coco_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_utils.ipynb.\n",
      "Converted 02_display.ipynb.\n",
      "Converted 03_dirView.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
